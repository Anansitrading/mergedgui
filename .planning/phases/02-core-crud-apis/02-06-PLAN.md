---
phase: 02-core-crud-apis
plan: 06
type: execute
wave: 2
wave_type: SEQUENTIAL
depends_on: ["02-02"]
files_modified:
  - server/app/workers/celery_app.py
  - server/app/workers/tasks.py
  - server/tests/test_workers.py
autonomous: true
difficulty: hard
---

<objective>
Implement Celery background workers for skill execution, habit scheduling, and reflex triggering.

Purpose: Skills execute asynchronously via Celery. Habits schedule via pg_cron → Celery. Reflexes trigger via webhook → Celery. This plan creates the task infrastructure.
</objective>

<context>
@server/app/services/database.py
@server/app/config.py
@database/003_habits_scheduler.sql
</context>

<tasks>
<task type="auto">
  <name>Create Celery app and background tasks</name>
  <files>
    server/app/workers/__init__.py
    server/app/workers/celery_app.py
    server/app/workers/tasks.py
    server/tests/test_workers.py
  </files>
  <action>
    Create Celery app with Redis broker:
    - celery_app.py: Celery instance with config from settings
    - tasks.py:
      * execute_skill_task(skill_id, user_id, input_data, execution_type, reference_id)
        — Calls LLM API (Gemini/Claude), records result via system_record_execution
      * process_habit_task(habit_id)
        — Fetches habit config, executes linked skill, updates next_run_at
      * process_reflex_task(reflex_id, trigger_data)
        — Evaluates conditions, executes linked skill if conditions met
      * cleanup_old_executions_task(days=90)
        — Periodic cleanup of old execution records
    All tasks use SECURITY DEFINER DB functions (no RLS context needed).
    Tests: mock LLM calls, verify task flow and error handling.
  </action>
  <done>Celery workers for skill execution, habit scheduling, and reflex triggering</done>
</task>
</tasks>

<output>
After completion, create `.planning/phases/02-core-crud-apis/02-06-SUMMARY.md`
</output>
